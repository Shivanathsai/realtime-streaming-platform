# ğŸ”¥ Real-Time Data Streaming Platform

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://python.org)
[![Kafka](https://img.shields.io/badge/Apache%20Kafka-3.6-231F20.svg)](https://kafka.apache.org)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-4169E1.svg)](https://postgresql.org)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://docker.com)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Ready-326CE5.svg)](https://kubernetes.io)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Event-driven data platform handling 500K+ events/hour with exactly-once semantics, implementing Complex Event Processing (CEP) patterns, windowing functions, and stateful transformations for real-time analytics and anomaly detection.**

---

## ğŸ“ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EVENT PRODUCERS â”‚     â”‚              APACHE KAFKA                          â”‚
â”‚                  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚ â€¢ Transactions   â”‚â”€â”€â”€â”€â–¶â”‚  â”‚raw-eventsâ”‚ â”‚enriched- â”‚ â”‚  alerts  â”‚          â”‚
â”‚ â€¢ User Activity  â”‚     â”‚  â”‚(6 parts) â”‚ â”‚ events   â”‚ â”‚(3 parts) â”‚          â”‚
â”‚ â€¢ IoT Sensors    â”‚     â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”˜          â”‚
â”‚ â€¢ API Calls      â”‚     â”‚       â”‚            â”‚            â”‚                  â”‚
â”‚                  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚            â”‚            â”‚
                                 â–¼            â”‚            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         STREAM PROCESSOR                    â”‚
                    â”‚                                            â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Windowingâ”‚ â”‚   CEP    â”‚ â”‚  State   â”‚  â”‚
                    â”‚  â”‚          â”‚ â”‚  Engine  â”‚ â”‚  Store   â”‚  â”‚
                    â”‚  â”‚â€¢ Tumblingâ”‚ â”‚          â”‚ â”‚          â”‚  â”‚
                    â”‚  â”‚â€¢ Sliding â”‚ â”‚â€¢ Velocityâ”‚ â”‚â€¢ Redis   â”‚  â”‚
                    â”‚  â”‚â€¢ Session â”‚ â”‚â€¢ Anomaly â”‚ â”‚â€¢ RocksDB â”‚  â”‚
                    â”‚  â”‚          â”‚ â”‚â€¢ Travel  â”‚ â”‚  backed  â”‚  â”‚
                    â”‚  â”‚          â”‚ â”‚â€¢ Burst   â”‚ â”‚          â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼            â–¼                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ PostgreSQL â”‚ â”‚ Grafana  â”‚  â”‚  Alert       â”‚
            â”‚ (Events +  â”‚ â”‚Dashboard â”‚  â”‚  Routing     â”‚
            â”‚  Alerts)   â”‚ â”‚          â”‚  â”‚  (Webhook)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”‘ Key Features

- **Exactly-Once Semantics** â€” Idempotent producers + manual offset commit + transactional reads
- **Complex Event Processing** â€” 5 CEP patterns: velocity spike, amount anomaly, impossible travel, rapid-fire burst, merchant diversity spike
- **Windowing Functions** â€” Tumbling (fixed), sliding (overlapping), and session (activity-based) windows
- **Stateful Transformations** â€” Redis-backed state store with TTL, Welford's online statistics, fault-tolerant checkpointing
- **Dead Letter Queue** â€” Automatic routing of failed events for retry/investigation
- **Batched Sink** â€” PostgreSQL consumer with bulk inserts (500 events/batch) for sustained throughput
- **Full Observability** â€” Prometheus metrics, Grafana dashboards, structured JSON logging
- **Kubernetes-Ready** â€” HPA auto-scaling on consumer lag, liveness/readiness probes

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|----------|-------------|
| Messaging | Apache Kafka 3.6 (confluent-kafka), 6-partition topics |
| Processing | Python 3.12, Pydantic, orjson, structlog |
| Storage | PostgreSQL 16, Redis 7 (state store) |
| Observability | Prometheus, Grafana, structured JSON logging |
| Infrastructure | Docker Compose, Kubernetes (HPA), GitHub Actions |
| API | FastAPI (health/metrics endpoints) |

## ğŸ“ Project Structure

```
realtime-streaming-platform/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                 # Pydantic config with env var support
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producers/
â”‚   â”‚   â””â”€â”€ transaction_producer.py # Event generator (500+ EPS, anomaly injection)
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ stream_processor.py     # Main pipeline: enrich â†’ window â†’ CEP â†’ route
â”‚   â”‚   â”œâ”€â”€ windowing.py            # Tumbling, sliding, session windows
â”‚   â”‚   â””â”€â”€ cep_engine.py           # 5 CEP patterns with Welford's online stats
â”‚   â”œâ”€â”€ consumers/
â”‚   â”‚   â”œâ”€â”€ postgres_sink.py        # Batched DB writer (500/batch, 5s flush)
â”‚   â”‚   â””â”€â”€ database.py             # SQLAlchemy models, indexes, materialized views
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ events.py               # Pydantic schemas (RawEvent, Alert, WindowAggregate)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ kafka_client.py         # Producer/Consumer wrappers, topic management
â”‚   â”‚   â”œâ”€â”€ state_store.py          # Redis-backed state with TTL and checkpointing
â”‚   â”‚   â”œâ”€â”€ metrics.py              # Prometheus counters, histograms, gauges
â”‚   â”‚   â””â”€â”€ logging.py              # structlog JSON logging
â”‚   â””â”€â”€ api.py                      # FastAPI health/metrics endpoints
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_windowing.py           # Window function tests (10 tests)
â”‚   â”œâ”€â”€ test_cep.py                 # CEP pattern tests (8 tests)
â”‚   â””â”€â”€ test_state_and_models.py    # State store + model tests (10 tests)
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚   â””â”€â”€ kubernetes/
â”‚       â””â”€â”€ deployments.yaml        # Deployments, HPA, ConfigMap, Service
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init_db.sql                 # Materialized views for dashboards
â”œâ”€â”€ docker-compose.yml              # Full stack: Kafka, PG, Redis, Grafana, app
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

### Run Full Stack (Docker Compose)
```bash
git clone https://github.com/Shivanathsai/Real-Time-Streaming-Platform.git
cd Real-Time-Streaming-Platform

# Start everything â€” Kafka, PostgreSQL, Redis, Grafana, app services
docker-compose up -d

# Watch logs
docker-compose logs -f stream-processor

# View Kafka UI at http://localhost:8080
# View Grafana at http://localhost:3000 (admin/admin)
```

### Run Tests Locally
```bash
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
python -m pytest tests/ -v
```

### Run Individual Components
```bash
# Producer â€” generate 500 events/sec
python -m src.producers.transaction_producer --eps 500

# Stream Processor
python -m src.processors.stream_processor

# PostgreSQL Sink
python -m src.consumers.postgres_sink
```

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| Throughput | 500K+ events/hour (140+ EPS sustained) |
| Processing Latency (p99) | < 50ms per event |
| Exactly-Once Guarantee | Idempotent producer + manual commit |
| Alert Detection Latency | < 2 seconds from event to alert |
| Sink Batch Write | 500 events/batch, ~5ms per batch |
| State Store Keys | 50K+ concurrent user states |
| Kafka Partitions | 6 per topic (parallel consumers) |

## ğŸ§© CEP Patterns

| Pattern | Description | Severity |
|---------|-------------|----------|
| Velocity Spike | > N events per user in 1-hour window | HIGH |
| Amount Anomaly | Transaction > 3Ïƒ from user's rolling mean | MEDIUM-HIGH |
| Impossible Travel | Consecutive events imply > 900 km/h travel | CRITICAL |
| Rapid-Fire Burst | N+ events within 10 seconds | HIGH |
| Merchant Diversity | 8+ distinct merchants in recent activity | MEDIUM |

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.
